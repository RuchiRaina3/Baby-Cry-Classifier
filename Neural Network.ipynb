{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuchiRaina3/Baby-Cry-Project/blob/main/Neural%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification is done using Sequential Neural Network\n",
        "It has five layers. First four layers have relu activation function and fifth layer has the softmax activation function.\n",
        "\n",
        "### Features extracted are MFCC. \n",
        "Mel-frequency cepstral coefficients (MFCCs) are coefficients that collectively make up an MFC. For that I have used librosa.feature.mfcc(). It will return 125 MFCCs"
      ],
      "metadata": {
        "id": "CpIFwsWFnTie"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ODcvZ1Kk_XW",
        "outputId": "fa57a4ee-bfc5-45fa-f78f-142949336b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqQqCLgKFd6V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import array\n",
        "import librosa\n",
        "\n",
        "import sys, time, os, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import re\n",
        "\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense, BatchNormalization\n",
        "from keras.layers.merge import add\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "risszNltMy3U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Read the Excel File\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Baby Cry Project/Baby Cry Data.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm_CiNQWHKq5"
      },
      "outputs": [],
      "source": [
        "audio_path=[]\n",
        "for i in range (len(data)):\n",
        "  a=data.iloc[i][0]\n",
        "  audio_path.append(a)\n",
        "  i=i+1\n",
        "  # print(a)\n",
        "\n",
        "label=[]\n",
        "for i in range (len(data)):\n",
        "  a=data.iloc[i][1]\n",
        "  label.append(a)\n",
        "  i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhvLuuNgE5Mg"
      },
      "outputs": [],
      "source": [
        "#Function For Feature Extraction\n",
        "def features_extractor(file):\n",
        "    #load the file (audio)\n",
        "    audio, sample_rate = librosa.load(file_name, sr=8000) \n",
        "    #we extract mfcc\n",
        "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=125)\n",
        "    #in order to find out scaled feature we do mean of transpose of value\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "    return mfccs_scaled_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtzbjU0pNNt6"
      },
      "outputs": [],
      "source": [
        "### Now we iterate through every audio file and extract features \n",
        "### using Mel-Frequency Cepstral Coefficients\n",
        "extracted_features=[]\n",
        "for i in range(len(data)):\n",
        "  file_name = data.iloc[i][0]\n",
        "  final_class_labels= data.iloc[i][1] \n",
        "  data=features_extractor(file_name)\n",
        "  extracted_features.append([data,final_class_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEZwMcXGOH9r"
      },
      "outputs": [],
      "source": [
        "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC9e9LwPnJQw"
      },
      "outputs": [],
      "source": [
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn-kFs0pOHvg"
      },
      "outputs": [],
      "source": [
        "### Split the dataset into independent and dependent dataset\n",
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['class'].tolist())\n",
        "### Label Encoding -> Label Encoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))\n",
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYOX3E3YCqHo"
      },
      "outputs": [],
      "source": [
        "### No of classes\n",
        "num_labels=y.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFTlmNlBTS0x"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "###first layer\n",
        "model.add(Dense(400,input_shape=(125,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###second layer\n",
        "model.add(Dense(300))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###third layer\n",
        "model.add(Dense(200))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###fourth layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###final layer\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zyx93YY9bEaN"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVvgsyqxJFMr"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "num_epochs = 3000\n",
        "\n",
        "num_batch_size = 53\n",
        "\n",
        "# checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/baby_cry_4_sec_audio/checkpoint', \n",
        "                              #  verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "# model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=1)\n",
        "duration = datetime.now() - start\n",
        "model.save('model')\n",
        "print(\"Training completed in time: \", duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRWUdjZ_Ts0p",
        "outputId": "0ded68b1-4908-449f-e1a1-52c0d3741461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8352941274642944\n"
          ]
        }
      ],
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUVZswFh0xmd",
        "outputId": "7b6ef1a8-9dcc-470f-d882-6f506e177d9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6455330848693848, 0.8352941274642944]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5AHdsyI1Gnm"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bda-hLD6rMU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79399df-8c89-4400-accd-09593a6d7bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 0 1 2 2 0 3 4 4 0 3 1 4 4 2 2 4 4 3 0 0 3 0 4 4 4 2 2 2 4 0 3 3 2 4 0\n",
            " 1 2 4 4 3 1 4 2 2 2 2 4 2 0 4 3 4 2 4 0 0 4 1 4 3 0 2 2 1 2 2 2 1 4 4 0 0\n",
            " 0 0 4 0 2 4 3 3 3 4 0]\n",
            "[2 4 0 1 2 2 0 3 2 3 0 2 1 3 4 2 2 4 4 3 0 0 3 0 4 4 3 2 2 2 4 0 3 3 2 4 0\n",
            " 1 2 4 0 3 0 4 2 2 2 2 3 2 0 4 3 4 2 4 0 0 4 1 3 3 0 2 2 2 2 2 4 4 4 4 0 0\n",
            " 0 0 4 0 2 4 3 3 3 4 0]\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(X_test) \n",
        "# print(pred)\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "label = np.argmax(y_test,axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E26b1mjLrWhO"
      },
      "outputs": [],
      "source": [
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUJixInJrqvh",
        "outputId": "9ed19433-5be1-4fa3-fd18-db62be72cb0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83.52941176470588"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "accuracy_metric(label,pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}